{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.airbnb.ca/s/Bridgeland~Riverside--Calgary--Alberta--Canada/homes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to start the web driver\n",
    "def init_driver():\n",
    "    options = Options()\n",
    "    ## Disable images to speed up the process\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "## Function to close the translation pop-up\n",
    "def close_translation(driver):\n",
    "    close_button = '//div[@class=\"c1lbtiq8 atm_mk_stnw88 atm_9s_1txwivl atm_fq_1tcgj5g atm_wq_kb7nvz atm_tk_1tcgj5g dir dir-ltr\"]'\n",
    "    try:\n",
    "        close = driver.find_element(By.XPATH, close_button)\n",
    "        close.click()\n",
    "    except NoSuchElementException:\n",
    "        ## if the pop-up is not found, pass\n",
    "        pass\n",
    "\n",
    "\n",
    "## Function to get the click on the \"Accept Cookies\" button\n",
    "def accept_cookies(driver):\n",
    "    cookies_button_class = '//div[@class=\"b16xa5oq atm_gi_1pzushe atm_jb_8wlvj5__oggzyc atm_gi_idpfg4__oggzyc atm_jb_rvwng3__1v156lz i1ckokof atm_h0_1gibeiw__oggzyc dir dir-ltr\"][2]'\n",
    "    try:\n",
    "        cookies = driver.find_element(By.XPATH, cookies_button_class)\n",
    "        cookies.click()\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strarting with getting urls of all the listings from the 15 pages that exist. Along with the urls, we will store the price shown on the lisiting and the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_urls_class = '//a[@class=\"l1ovpqvx atm_1he2i46_1k8pnbi_10saat9 atm_yxpdqi_1pv6nv4_10saat9 atm_1a0hdzc_w1h1e8_10saat9 atm_2bu6ew_929bqk_10saat9 atm_12oyo1u_73u7pn_10saat9 atm_fiaz40_1etamxe_10saat9 bn2bl2p atm_5j_223wjw atm_9s_1ulexfb atm_e2_1osqo2v atm_fq_idpfg4 atm_mk_stnw88 atm_tk_idpfg4 atm_vy_1osqo2v atm_26_1j28jx2 atm_3f_glywfm atm_kd_glywfm atm_3f_glywfm_jo46a5 atm_l8_idpfg4_jo46a5 atm_gi_idpfg4_jo46a5 atm_3f_glywfm_1icshfk atm_kd_glywfm_19774hq atm_uc_aaiy6o_1w3cfyq_oggzyc atm_70_1b8lkes_1w3cfyq_oggzyc atm_uc_glywfm_1w3cfyq_pynvjw atm_uc_aaiy6o_pfnrn2_ivgyl9 atm_70_1b8lkes_pfnrn2_ivgyl9 atm_uc_glywfm_pfnrn2_61fwbc dir dir-ltr\"]'\n",
    "\n",
    "next_page_class = '//a[@class=\"l1ovpqvx atm_1he2i46_1k8pnbi_10saat9 atm_yxpdqi_1pv6nv4_10saat9 atm_1a0hdzc_w1h1e8_10saat9 atm_2bu6ew_929bqk_10saat9 atm_12oyo1u_73u7pn_10saat9 atm_fiaz40_1etamxe_10saat9 c1ytbx3a atm_mk_h2mmj6 atm_9s_1txwivl atm_h_1h6ojuz atm_fc_1h6ojuz atm_bb_idpfg4 atm_26_1j28jx2 atm_3f_glywfm atm_7l_hkljqm atm_gi_idpfg4 atm_l8_idpfg4 atm_uc_10d7vwn atm_kd_glywfm atm_gz_8tjzot atm_uc_glywfm__1rrf6b5 atm_26_zbnr2t_1rqz0hn_uv4tnr atm_tr_kv3y6q_csw3t1 atm_26_zbnr2t_1ul2smo atm_3f_glywfm_jo46a5 atm_l8_idpfg4_jo46a5 atm_gi_idpfg4_jo46a5 atm_3f_glywfm_1icshfk atm_kd_glywfm_19774hq atm_70_glywfm_1w3cfyq atm_uc_aaiy6o_9xuho3 atm_70_18bflhl_9xuho3 atm_26_zbnr2t_9xuho3 atm_uc_glywfm_9xuho3_1rrf6b5 atm_70_glywfm_pfnrn2_1oszvuo atm_uc_aaiy6o_1buez3b_1oszvuo atm_70_18bflhl_1buez3b_1oszvuo atm_26_zbnr2t_1buez3b_1oszvuo atm_uc_glywfm_1buez3b_1o31aam atm_7l_1wxwdr3_1o5j5ji atm_9j_13gfvf7_1o5j5ji atm_26_1j28jx2_154oz7f atm_92_1yyfdc7_vmtskl atm_9s_1ulexfb_vmtskl atm_mk_stnw88_vmtskl atm_tk_1ssbidh_vmtskl atm_fq_1ssbidh_vmtskl atm_tr_pryxvc_vmtskl atm_vy_1vi7ecw_vmtskl atm_e2_1vi7ecw_vmtskl atm_5j_1ssbidh_vmtskl atm_mk_h2mmj6_1ko0jae dir dir-ltr\"]'\n",
    "\n",
    "price_class = '//div[@class=\"_1jo4hgw\"]'\n",
    "\n",
    "ratings_class = (\n",
    "    '//div[@class=\"t1a9j9y7 atm_da_1ko3t4y atm_dm_kb7nvz atm_fg_h9n0ih dir dir-ltr\"]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get the listing URL\n",
    "def get_listing_url(driver, listing_urls_class):\n",
    "    listing_urls = []\n",
    "    try:\n",
    "        listings = driver.find_elements(By.XPATH, listing_urls_class)\n",
    "        for listing in listings:\n",
    "            listing_urls.append(listing.get_attribute(\"href\"))\n",
    "    except NoSuchElementException:\n",
    "        listing_urls.append(\"-\")\n",
    "    return listing_urls\n",
    "\n",
    "## Function to get the price of the listing\n",
    "def get_price(driver, price_class):\n",
    "    prices = []\n",
    "    try:\n",
    "        price = driver.find_elements(By.XPATH, price_class)\n",
    "        for p in price:\n",
    "            prices.append(p.text)\n",
    "    except NoSuchElementException:\n",
    "        prices.append(\"-\")\n",
    "    return prices\n",
    "\n",
    "## Function to get the ratings of the listing\n",
    "def get_ratings(driver, ratings_class):\n",
    "    ratings = []\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH, ratings_class)\n",
    "        for r in rating:\n",
    "            ratings.append(r.text)\n",
    "    except NoSuchElementException:\n",
    "        ratings.append(\"-\")\n",
    "    return ratings\n",
    "\n",
    "## Function to get the next page\n",
    "def get_next_page(driver, next_page_class):\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, next_page_class)\n",
    "        next_page.click()\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get the URLs, prices and ratings\n",
    "def get_urls(\n",
    "    num_pages, url, listing_urls_class, next_page_class, price_class, ratings_class\n",
    "):\n",
    "\n",
    "    driver = init_driver()\n",
    "    driver.get(url)\n",
    "    close_translation(driver)\n",
    "    accept_cookies(driver)\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        listing_urls = get_listing_url(driver, listing_urls_class)\n",
    "        prices = get_price(driver, price_class)\n",
    "        ratings = get_ratings(driver, ratings_class)\n",
    "        try:\n",
    "            if i == num_pages - 1:  ## if it is the last page, break\n",
    "                driver.quit()\n",
    "                break\n",
    "            else:\n",
    "                get_next_page(driver, next_page_class)\n",
    "        except NoSuchElementException:\n",
    "            print(\"Error going to new page\")\n",
    "            driver.quit()\n",
    "            break\n",
    "    driver.quit()\n",
    "    return listing_urls, prices, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_urls, prices, ratings = get_urls(\n",
    "    15, url, listing_urls_class, next_page_class, price_class, ratings_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df = pd.DataFrame(\n",
    "    data={\"urls\": listing_urls, \"prices\": prices, \"ratings\": ratings}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df.to_csv(\"../data/urls_prices_ratings.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the urls, we can start scraping each listing and get desired data. The classes of data we want are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"tagline\": '//div[@class=\"_1czgyoo\"]',\n",
    "    \"basic_description\": '//div[@class=\"toieuka atm_c8_2x1prs atm_g3_1jbyh58 atm_fr_11a07z3 atm_cs_10d11i2 atm_c8_sz6sci__oggzyc atm_g3_17zsb9a__oggzyc atm_fr_kzfbxz__oggzyc dir dir-ltr\"]',\n",
    "    \"basic_info\": '//div[@class=\"o1kjrihn atm_c8_km0zk7 atm_g3_18khvle atm_fr_1m9t47k atm_h3_1y44olf atm_c8_2x1prs__oggzyc atm_g3_1jbyh58__oggzyc atm_fr_11a07z3__oggzyc dir dir-ltr\"]',\n",
    "    \"description\": '//div[@class=\"d1isfkwk atm_vv_1jtmq4 atm_w4_1hnarqo dir dir-ltr\"]',\n",
    "    \"fee\": '//div[@class=\"_1cvivhm\"]',\n",
    "    \"amenities_button\": '//button[@class=\"l1ovpqvx atm_1he2i46_1k8pnbi_10saat9 atm_yxpdqi_1pv6nv4_10saat9 atm_1a0hdzc_w1h1e8_10saat9 atm_2bu6ew_929bqk_10saat9 atm_12oyo1u_73u7pn_10saat9 atm_fiaz40_1etamxe_10saat9 b1sef8f2 atm_9j_tlke0l atm_9s_1o8liyq atm_gi_idpfg4 atm_mk_h2mmj6 atm_r3_1h6ojuz atm_rd_glywfm atm_3f_uuagnh atm_70_5j5alw atm_vy_1wugsn5 atm_tl_1gw4zv3 atm_9j_13gfvf7_1o5j5ji c3dg75g atm_bx_48h72j atm_c8_2x1prs atm_g3_1jbyh58 atm_fr_11a07z3 atm_cs_10d11i2 atm_5j_t09oo2 atm_6h_t94yts atm_66_nqa18y atm_kd_glywfm atm_uc_1lizyuv atm_r2_1j28jx2 atm_jb_1fkumsa atm_4b_1qnzqti atm_26_1qwqy05 atm_7l_jt7fhx atm_l8_1vkzbvs atm_uc_glywfm__1rrf6b5 atm_kd_glywfm_1w3cfyq atm_uc_aaiy6o_1w3cfyq atm_3f_glywfm_e4a3ld atm_l8_idpfg4_e4a3ld atm_gi_idpfg4_e4a3ld atm_3f_glywfm_1r4qscq atm_kd_glywfm_6y7yyg atm_uc_glywfm_1w3cfyq_1rrf6b5 atm_kd_glywfm_pfnrn2_1oszvuo atm_uc_aaiy6o_pfnrn2_1oszvuo atm_3f_glywfm_1icshfk_1oszvuo atm_l8_idpfg4_1icshfk_1oszvuo atm_gi_idpfg4_1icshfk_1oszvuo atm_3f_glywfm_b5gff8_1oszvuo atm_kd_glywfm_2by9w9_1oszvuo atm_uc_glywfm_pfnrn2_1o31aam atm_tr_18md41p_csw3t1 atm_k4_kb7nvz_1o5j5ji atm_4b_1qnzqti_1w3cfyq atm_7l_jt7fhx_1w3cfyq atm_70_1e7pbig_1w3cfyq atm_4b_1qnzqti_pfnrn2_1oszvuo atm_7l_jt7fhx_pfnrn2_1oszvuo atm_70_1e7pbig_pfnrn2_1oszvuo atm_4b_lb1gtz_1nos8r_uv4tnr atm_26_zbnr2t_1nos8r_uv4tnr atm_7l_jt7fhx_1nos8r_uv4tnr atm_4b_1k0ymf0_4fughm_uv4tnr atm_26_1qwqy05_4fughm_uv4tnr atm_7l_9vytuy_4fughm_uv4tnr atm_4b_lb1gtz_csw3t1 atm_26_zbnr2t_csw3t1 atm_7l_jt7fhx_csw3t1 atm_4b_1k0ymf0_1o5j5ji atm_26_1qwqy05_1o5j5ji atm_7l_9vytuy_1o5j5ji dir dir-ltr\"]',\n",
    "    \"close_amenities\": '//div[@class=\"c11vnb9k atm_mk_stnw88 atm_9s_1txwivl atm_tk_exct8b atm_fq_1tcgj5g atm_wq_kb7nvz atm_1wn1q82_xond3e atm_tk_1tcgj5g__oggzyc dir dir-ltr\"]',\n",
    "    \"amenities\": '//div[@class=\"twad414 atm_7l_jt7fhx atm_9j_1kw7nm4 atm_bx_48h72j atm_c8_2x1prs atm_g3_1jbyh58 atm_fr_11a07z3 dir dir-ltr\"]',\n",
    "    \"superhost\": '//div[@class=\"sj1ia5j atm_c8_1cbyki6 atm_g3_1k8s52q atm_cs_10d11i2 dir dir-ltr\"]',\n",
    "    \"service_ratings\": '//div[@class=\"vjb6p42 atm_c8_vvn7el atm_g3_k2d186 atm_fr_1vi102y dir dir-ltr\"]',\n",
    "    \"service_ratings_1\": '//div[@class=\"l925rvg atm_9s_1txwivl atm_ar_1bp4okc atm_cx_yh40bf dir dir-ltr\"]',\n",
    "    \"ratings_section\": \"/html/body/div[5]/div/div/div[1]/div/div[2]/div/div/div/div[1]/main/div/div[1]/div[4]/div/div\",\n",
    "    \"response_rate\": '//div[@class=\"h1iimu7q atm_9s_1txwivl atm_ar_1bp4okc atm_cx_exct8b dir dir-ltr\"]',\n",
    "    \"host_description\": '//div[@class=\"h2s2exi atm_9s_1txwivl atm_ar_1bp4okc atm_gq_1fwxnve atm_cx_1tcgj5g atm_cx_1vi7ecw__oggzyc dir dir-ltr\"]',\n",
    "    \"house_rules\": '//div[@class=\"c1e17v3g atm_7l_dezgoh atm_bx_48h72j atm_cs_6adqpa atm_c8_2x1prs atm_g3_1jbyh58 atm_fr_11a07z3 dir dir-ltr\"]',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Tagline function\n",
    "def get_tagline(driver):\n",
    "    tagline = \"\"\n",
    "    try:\n",
    "        tagline_found = driver.find_element(By.XPATH, classes[\"tagline\"])\n",
    "        tagline = tagline_found.text\n",
    "    except NoSuchElementException:\n",
    "        tagline = \"No tagline found\"\n",
    "    return tagline\n",
    "\n",
    "\n",
    "## Get Basic Description function\n",
    "def get_basic_description(driver):\n",
    "    basic_description = \"\"\n",
    "    try:\n",
    "        basic_description_found = driver.find_element(\n",
    "            By.XPATH, classes[\"basic_description\"]\n",
    "        )\n",
    "        basic_description = basic_description_found.text\n",
    "    except NoSuchElementException:\n",
    "        basic_description = \"No basic description found\"\n",
    "    return basic_description\n",
    "\n",
    "\n",
    "## Get Basic Info function\n",
    "def get_basic_info(driver):\n",
    "    basic_info = \"\"\n",
    "    try:\n",
    "        basic_info_found = driver.find_element(By.XPATH, classes[\"basic_info\"])\n",
    "        basic_info = basic_info_found.text\n",
    "    except NoSuchElementException:\n",
    "        basic_info = \"No basic info found\"\n",
    "    return basic_info\n",
    "\n",
    "\n",
    "## Get Description function\n",
    "def get_description(driver):\n",
    "    description = \"\"\n",
    "    try:\n",
    "        description_found = driver.find_element(By.XPATH, classes[\"description\"])\n",
    "        description = description_found.text\n",
    "    except NoSuchElementException:\n",
    "        description = \"No description found\"\n",
    "    return description\n",
    "\n",
    "\n",
    "## Get Fee function\n",
    "def get_fee(driver):\n",
    "    fee = \"\"\n",
    "    try:\n",
    "        fee_found = driver.find_element(By.XPATH, classes[\"fee\"])\n",
    "        fee = fee_found.text\n",
    "    except NoSuchElementException:\n",
    "        fee = \"No fee found\"\n",
    "    return fee\n",
    "\n",
    "\n",
    "## Get Superhost function\n",
    "def get_superhost(driver):\n",
    "    superhost = \"\"\n",
    "    try:\n",
    "        superhost_found = driver.find_element(By.XPATH, classes[\"superhost\"])\n",
    "        superhost = superhost_found.text\n",
    "    except NoSuchElementException:\n",
    "        superhost = \"No superhost found\"\n",
    "    return superhost\n",
    "\n",
    "\n",
    "## Get ratings function\n",
    "def get_service_ratings(driver):\n",
    "    service_ratings = \"\"\n",
    "    ratings_found = []\n",
    "    try:\n",
    "        ratings_section = driver.find_element(\n",
    "            By.XPATH,\n",
    "            classes[\"ratings_section\"],\n",
    "        )\n",
    "        # Scroll to the ratings section\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", ratings_section)\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Wait for ratings to be visible\n",
    "        rating = driver.find_elements(By.XPATH, classes[\"service_ratings_1\"])\n",
    "        for r in rating:\n",
    "            ratings_found.append(r.text)\n",
    "        service_ratings = ratings_found\n",
    "    except NoSuchElementException:\n",
    "        service_ratings = \"No service ratings found\"\n",
    "    return service_ratings\n",
    "\n",
    "\n",
    "## Response rate function\n",
    "def get_response_rate(driver):\n",
    "    response_rate = \"\"\n",
    "    try:\n",
    "        response_rate_found = driver.find_element(By.XPATH, classes[\"response_rate\"])\n",
    "        response_rate = response_rate_found.text\n",
    "    except NoSuchElementException:\n",
    "        response_rate = \"No response rate found\"\n",
    "    return response_rate\n",
    "\n",
    "\n",
    "## Host description function\n",
    "def get_host_description(driver):\n",
    "    host_description = \"\"\n",
    "    try:\n",
    "        host_description_found = driver.find_element(\n",
    "            By.XPATH, classes[\"host_description\"]\n",
    "        ).text\n",
    "        host_description = host_description_found\n",
    "    except NoSuchElementException:\n",
    "        host_description = \"No host description found\"\n",
    "    return host_description\n",
    "\n",
    "\n",
    "## Get amenities\n",
    "def get_amenities(driver):\n",
    "    amenities = \"\"\n",
    "    amenities_in_place = []\n",
    "    ## click amenities button\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        amenities_button = driver.find_element(By.XPATH, classes[\"amenities_button\"])\n",
    "        time.sleep(2)\n",
    "        amenities_button.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"No amenities button found\")\n",
    "    ## get amenities\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        amenities_found = driver.find_elements(By.XPATH, classes[\"amenities\"])\n",
    "        for amenity in amenities_found:\n",
    "            amenities_in_place.append(amenity.text)\n",
    "        amenities = amenities_in_place\n",
    "    except NoSuchElementException:\n",
    "        amenities = \"No amenities found\"\n",
    "    ## close amenities\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        close_amenities = driver.find_element(By.XPATH, classes[\"close_amenities\"])\n",
    "        time.sleep(2)\n",
    "        close_amenities.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"No close amenities button found\")\n",
    "    return amenities\n",
    "\n",
    "\n",
    "## Get house rules\n",
    "def get_house_rules(driver):\n",
    "    house_rules = \"\"\n",
    "    try:\n",
    "        house_rules_found = driver.find_element(By.XPATH, classes[\"house_rules\"])\n",
    "        house_rules = house_rules_found.text\n",
    "    except NoSuchElementException:\n",
    "        house_rules = \"No house rules found\"\n",
    "    return house_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df = pd.read_csv(\"../data/urls_prices_ratings.csv\")\n",
    "urls = urls_df[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the data for one listing\n",
    "def scraper(\n",
    "    driver,\n",
    "    url,\n",
    "    tagline,\n",
    "    basic_description,\n",
    "    basic_info,\n",
    "    fee,\n",
    "    description,\n",
    "    amenities,\n",
    "    superhost,\n",
    "    service_ratings,\n",
    "    response_rate,\n",
    "    host_description,\n",
    "    house_rules,\n",
    "):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    close_translation(driver)\n",
    "    time.sleep(1)\n",
    "    accept_cookies(driver)\n",
    "    time.sleep(2)\n",
    "    tagline.append(get_tagline(driver))\n",
    "    basic_description.append(get_basic_description(driver))\n",
    "    basic_info.append(get_basic_info(driver))\n",
    "    fee.append(get_fee(driver))\n",
    "    description.append(get_description(driver))\n",
    "    amenities.append(get_amenities(driver))\n",
    "    superhost.append(get_superhost(driver))\n",
    "    service_ratings.append(get_service_ratings(driver))\n",
    "    response_rate.append(get_response_rate(driver))\n",
    "    host_description.append(get_host_description(driver))\n",
    "    house_rules.append(get_house_rules(driver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the data for multiple listings\n",
    "def listings_scraper(urls):\n",
    "    tagline = []\n",
    "    basic_description = []\n",
    "    basic_info = []\n",
    "    fee = []\n",
    "    description = []\n",
    "    amenities = []\n",
    "    superhost = []\n",
    "    service_ratings = []\n",
    "    response_rate = []\n",
    "    host_description = []\n",
    "    house_rules = []\n",
    "    driver = init_driver()\n",
    "    for url in urls:\n",
    "        scraper(\n",
    "            driver,\n",
    "            url,\n",
    "            tagline,\n",
    "            basic_description,\n",
    "            basic_info,\n",
    "            fee,\n",
    "            description,\n",
    "            amenities,\n",
    "            superhost,\n",
    "            service_ratings,\n",
    "            response_rate,\n",
    "            host_description,\n",
    "            house_rules,\n",
    "        )\n",
    "    driver.quit()\n",
    "    ## Create a dataframe\n",
    "    data = {\n",
    "        \"tagline\": tagline,\n",
    "        \"basic_description\": basic_description,\n",
    "        \"basic_info\": basic_info,\n",
    "        \"fee\": fee,\n",
    "        \"description\": description,\n",
    "        \"amenities\": amenities,\n",
    "        \"superhost\": superhost,\n",
    "        \"service_ratings\": service_ratings,\n",
    "        \"response_rate\": response_rate,\n",
    "        \"host_description\": host_description,\n",
    "        \"house_rules\": house_rules,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listings_scraper(urls)\n",
    "df.to_csv(\"../data/final_df.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
